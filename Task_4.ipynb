{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPb5dhEExYt2IwCQMTs0RyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orenshor/eCommerce_project/blob/master/Task_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mQryltofvCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a88875cf-3859-499a-ac9a-6be06486b111"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as T\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Sequential, Model, load_model, save_model\n",
        "from keras.layers.core import Dense, Lambda, Activation\n",
        "from keras.layers import Embedding, Input, Dense, merge, Reshape,  Flatten, Dropout\n",
        "from keras.optimizers import Adagrad, Adam, SGD, RMSprop, Adamax\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Multiply, Concatenate\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from time import time\n",
        "import multiprocessing as mp\n",
        "import sys\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk2Czt_Jf0Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F3l3-Wdf2HQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "1be71138-394c-4242-b62b-b1da96642f27"
      },
      "source": [
        "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
        "\n",
        "Enter your authorization code:\n",
        "··········\n",
        "Mounted at /content/drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-672e99ccf498>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No82V7XCf8ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RATING_DATA_TEST_FILE = MOVIELENS_DIR+'u.data'\n",
        "RATING_DATA_TRAIN_FILE = MOVIELENS_DIR+'u.data'\n",
        "RATINGS_CSV_TEST_FILE = 'u_emb.data'\n",
        "RATINGS_CSV_TRAIN_FILE = 'u_norm.data'\n",
        "MODEL_WEIGHTS_FILE = 'u_emb_weights.h5'\n",
        "MODEL_WEIGHTS_FILE_CORE = 'u_emb_weights'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gxz_LmLhxtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings = pd.read_csv(RATING_DATA_FILE, \n",
        "                    sep='\\t', \n",
        "                    engine='python', \n",
        "                    encoding='latin-1',\n",
        "                    names=['userid', 'movieid', 'rating', 'timestamp'])\n",
        "max_userid = ratings['userid'].drop_duplicates().max()\n",
        "max_movieid = ratings['movieid'].drop_duplicates().max()\n",
        "ratings['user_emb_id'] = ratings['userid'] - 1\n",
        "ratings['movie_emb_id'] = ratings['movieid'] - 1\n",
        "print(str(len(ratings))+' ratings loaded')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaPgyCVwhyA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings.to_csv(MOVIELENS_DIR+RATINGS_CSV_FILE, \n",
        "               sep='\\t', \n",
        "               header=True, \n",
        "               encoding='latin-1', \n",
        "               columns=['userid', 'movieid', 'rating', 'timestamp', 'user_emb_id', 'movie_emb_id'])\n",
        "print('Saved to'+MOVIELENS_DIR+RATINGS_CSV_FILE)\n",
        "#files.download(RATINGS_CSV_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkkJCOkShyG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ratings = pd.read_csv(RATING_DATA_FILE, \n",
        "#                    sep='\\t', \n",
        "#                    engine='python', \n",
        "#                    encoding='latin-1',\n",
        "#                    names=['userid', 'movieid', 'rating', 'timestamp'])\n",
        "max_userid = ratings['userid'].drop_duplicates().max()\n",
        "max_movieid = ratings['movieid'].drop_duplicates().max()\n",
        "ratings['user_emb_id'] = ratings['userid'] - 1\n",
        "ratings['movie_emb_id'] = ratings['movieid'] - 1\n",
        "ratings['rating_norm'] = ratings['rating']  * 0.2\n",
        "print(str(len(ratings))+' ratings loaded')\n",
        "ratings.to_csv(MOVIELENS_DIR+RATINGS_CSV_FILE_NORM, \n",
        "               sep='\\t', \n",
        "               header=True, \n",
        "               encoding='latin-1', \n",
        "               columns=['userid', 'movieid', 'rating', 'timestamp', 'user_emb_id', 'movie_emb_id','rating_norm'])\n",
        "print('Saved to '+RATINGS_CSV_FILE_NORM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKhpK_OGiD4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ratings are normalized between 0 to 1\n",
        "ratings_norm = pd.read_csv(MOVIELENS_DIR+RATINGS_CSV_FILE_NORM, \n",
        "                       sep='\\t', \n",
        "                       encoding='latin-1', \n",
        "                       usecols=['userid', 'movieid', 'user_emb_id', 'movie_emb_id', 'rating','rating_norm'])\n",
        "max_userid = ratings_norm['userid'].drop_duplicates().max()\n",
        "max_movieid = ratings_norm['movieid'].drop_duplicates().max()\n",
        "print(str(len(ratings)), 'ratings loaded.')\n",
        "print('users '+str(max_userid)+' items '+str(max_movieid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aorXjeIAiEAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Users = ratings['user_emb_id'].values\n",
        "Movies = ratings['movie_emb_id'].values\n",
        "Ratings = ratings['rating'].values\n",
        "Ratings_norm = ratings_norm['rating_norm']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX58mTv2f-ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ncf_model(num_users, num_items, latent_dim,hidden_dim,do):\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "\n",
        "    MF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
        "    MF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
        "    \n",
        "    # Crucial to flatten an embedding vector!\n",
        "    user_latent = Flatten()(MF_Embedding_User(user_input))\n",
        "    item_latent = Flatten()(MF_Embedding_Item(item_input))\n",
        "    \n",
        "    # Element-wise product of user and item embeddings\n",
        "    conc = Concatenate()([user_latent, item_latent])\n",
        "    drop = Dropout(0.5)(conc)\n",
        "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
        "    drop2  = Dropout(do)(hid1)\n",
        "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
        "    \n",
        "    \n",
        "    model = Model(input=[user_input, item_input], output=prediction)\n",
        "    print(\"ncf model\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}