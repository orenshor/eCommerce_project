{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOvBOU4BAZ7AuUiXhtQxPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orenshor/eCommerce_project/blob/master/task_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj_Lw7RdBYuv",
        "colab_type": "code",
        "outputId": "a37ef54a-0536-4712-aea7-e4ab15e97399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam, Adamax\n",
        "from keras.layers import Concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "punEIpwMBvi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RATING_DATA_TEST_FILE = \"u1.test\"\n",
        "RATING_DATA_TRAIN_FILE = \"u1.base\"\n",
        "MODEL_WEIGHTS_FILE = \"u_emb_weights.h5\"\n",
        "\n",
        "USER_DATA_FILE = 'u.user'\n",
        "MODEL_WEIGHTS_FILE_CORE = 'u_emb_weights'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5c3__4pCz1K",
        "colab_type": "code",
        "outputId": "4e7fc138-12d7-4681-cb5b-c68e6b92f52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#import of the data\n",
        "\n",
        "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "movie_cols = ['user_id','movie_id','rating','timestamp']\n",
        "\n",
        "# load users data\n",
        "user_data = pd.read_csv(USER_DATA_FILE, sep='|', engine='python', encoding='latin-1', names=user_cols)\n",
        "\n",
        "# replace values in the data\n",
        "user_data['gender'].replace(['F','M'],['0','1'],inplace=True)\n",
        "user_data['age'] = pd.cut(user_data['age'],bins=[0,18,25,30,40,50,100], labels=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
        "\n",
        "# load movies data\n",
        "ratings_train = pd.read_csv(RATING_DATA_TRAIN_FILE, sep='\\t', engine='python', encoding='latin-1', names=movie_cols)\n",
        "\n",
        "# marge users info and ratings \n",
        "ratings_train = pd.merge(ratings_train, user_data, on='user_id',how='inner')\n",
        "print(ratings_train.head())\n",
        "# train\n",
        "max_userid = ratings_train['user_id'].drop_duplicates().max()\n",
        "max_movieid = ratings_train['movie_id'].drop_duplicates().max()\n",
        "ratings_train['user_emb_id'] = ratings_train['user_id'] - 1\n",
        "ratings_train['movie_emb_id'] = ratings_train['movie_id'] - 1\n",
        "print(str(len(ratings_train))+' ratings loaded from train')\n",
        "\n",
        "# test\n",
        "ratings_test = pd.read_csv(RATING_DATA_TEST_FILE, sep='\\t',   engine='python', encoding='latin-1',  names=movie_cols)\n",
        "ratings_test = pd.merge(ratings_test, user_data, on='user_id', how='inner')\n",
        "print(ratings_test.head())\n",
        "ratings_test['user_emb_id'] = ratings_test['user_id'] - 1\n",
        "ratings_test['movie_emb_id'] = ratings_test['movie_id'] - 1\n",
        "print(str(len(ratings_test))+' ratings loaded from test')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  movie_id  rating  timestamp age gender  occupation zip_code\n",
            "0        1         1       5  874965758   1      1  technician    85711\n",
            "1        1         2       3  876893171   1      1  technician    85711\n",
            "2        1         3       4  878542960   1      1  technician    85711\n",
            "3        1         4       3  876893119   1      1  technician    85711\n",
            "4        1         5       3  889751712   1      1  technician    85711\n",
            "80000 ratings loaded from train\n",
            "   user_id  movie_id  rating  timestamp age gender  occupation zip_code\n",
            "0        1         6       5  887431973   1      1  technician    85711\n",
            "1        1        10       3  875693118   1      1  technician    85711\n",
            "2        1        12       5  878542960   1      1  technician    85711\n",
            "3        1        14       5  874965706   1      1  technician    85711\n",
            "4        1        17       3  875073198   1      1  technician    85711\n",
            "20000 ratings loaded from test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwdPQXcMN6PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train values\n",
        "train_users = ratings_train['user_emb_id'].values\n",
        "train_movies = ratings_train['movie_emb_id'].values\n",
        "train_ratings = ratings_train['rating'].values\n",
        "train_gender = ratings_train['gender'].values\n",
        "train_age = ratings_train['age'].values\n",
        "\n",
        "Test_Users = ratings_test['user_emb_id'].values\n",
        "Test_Movies = ratings_test['movie_emb_id'].values\n",
        "Test_Ratings = ratings_test['rating'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdEgcipNJD73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model from ex. 4 with adjustments\n",
        "def get_ncf_model_gen1(num_users, num_items, latent_dim, hidden_dim,do):\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "    gender_input = Input(shape=(1,), dtype='float32', name = 'gender_input')\n",
        "    age_input = Input(shape=(1,), dtype='float32', name = 'age_input')\n",
        "\n",
        "    NCF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
        "    NCF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
        "    \n",
        "    # Crucial to flatten an embedding vector!\n",
        "    user_latent = Flatten()(NCF_Embedding_User(user_input))\n",
        "    item_latent = Flatten()(NCF_Embedding_Item(item_input))\n",
        "    \n",
        "    # Concat user and item embeddings with gender\n",
        "    conc = Concatenate()([user_latent, item_latent, gender_input, age_input])\n",
        "    drop = Dropout(do)(conc)\n",
        "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
        "    drop2  = Dropout(do)(hid1)\n",
        "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
        "    \n",
        "    model = Model(inputs=[user_input, item_input, gender_input, age_input], outputs=prediction)\n",
        "    print(\"ncf model gender 1\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n68Uz1BbIn02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model, model_name):\n",
        "    model_json = model.to_json()\n",
        "    with open(model_name + \".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model.save_weights(model_name + \".h5\")\n",
        "\n",
        "def load_model(model_name):\n",
        "    json_file = open(model_name + '.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(model_name + \".h5\")\n",
        "    return loaded_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Lxo5rCJ1VU",
        "colab_type": "code",
        "outputId": "ccc5221c-72b1-4705-ed97-36aacc9b99c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "K_LATENT = 20\n",
        "hidden_dim = 20\n",
        "do = 0.3\n",
        "\n",
        "NCF_G_model1 = get_ncf_model_gen1(max_userid, max_movieid, K_LATENT,hidden_dim, do)\n",
        "NCF_G_model1.compile(loss='mse',optimizer=Adamax(),metrics=['mae'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ncf model gender 1\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "user_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "item_input (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "user_embedding (Embedding)      (None, 1, 20)        18860       user_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "item_embedding (Embedding)      (None, 1, 20)        33640       item_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 20)           0           user_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 20)           0           item_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "gender_input (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "age_input (InputLayer)          (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 42)           0           flatten_5[0][0]                  \n",
            "                                                                 flatten_6[0][0]                  \n",
            "                                                                 gender_input[0][0]               \n",
            "                                                                 age_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 20)           860         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 20)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 1)            21          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 53,381\n",
            "Trainable params: 53,381\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyk_MaFSL9Bk",
        "colab_type": "code",
        "outputId": "a38d7ab1-84de-4ee0-e06f-20b4add59d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "callbacks_ncfg1 = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE + '_ncfg_' + str(do) + '_' + str(K_LATENT) + '.h5', save_best_only=True)]\n",
        "history_ncfg1 = NCF_G_model1.fit([train_users, train_movies, train_gender, train_age], train_ratings,\n",
        "                                 epochs=100, validation_split=0.1, verbose=1, callbacks=callbacks_ncfg1, batch_size = 32)\n",
        "save_model(NCF_G_model1, \"task5_model1\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 72000 samples, validate on 8000 samples\n",
            "Epoch 1/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 1.9039 - mae: 1.0901 - val_loss: 1.2438 - val_mae: 0.9070\n",
            "Epoch 2/100\n",
            "72000/72000 [==============================] - 3s 48us/step - loss: 1.1619 - mae: 0.8618 - val_loss: 1.1330 - val_mae: 0.8692\n",
            "Epoch 3/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 1.0264 - mae: 0.8095 - val_loss: 1.0737 - val_mae: 0.8463\n",
            "Epoch 4/100\n",
            "72000/72000 [==============================] - 3s 48us/step - loss: 0.9547 - mae: 0.7789 - val_loss: 1.0442 - val_mae: 0.8331\n",
            "Epoch 5/100\n",
            "72000/72000 [==============================] - 3s 48us/step - loss: 0.9176 - mae: 0.7628 - val_loss: 1.0276 - val_mae: 0.8260\n",
            "Epoch 6/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.9003 - mae: 0.7542 - val_loss: 1.0349 - val_mae: 0.8310\n",
            "Epoch 7/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8852 - mae: 0.7467 - val_loss: 1.0007 - val_mae: 0.8114\n",
            "Epoch 8/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8715 - mae: 0.7390 - val_loss: 1.0139 - val_mae: 0.8207\n",
            "Epoch 9/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8614 - mae: 0.7328 - val_loss: 1.0200 - val_mae: 0.8228\n",
            "Epoch 10/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8557 - mae: 0.7304 - val_loss: 1.0083 - val_mae: 0.8149\n",
            "Epoch 11/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8487 - mae: 0.7264 - val_loss: 1.0114 - val_mae: 0.8182\n",
            "Epoch 12/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8449 - mae: 0.7244 - val_loss: 1.0146 - val_mae: 0.8203\n",
            "Epoch 13/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8418 - mae: 0.7229 - val_loss: 1.0217 - val_mae: 0.8265\n",
            "Epoch 14/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8408 - mae: 0.7224 - val_loss: 1.0305 - val_mae: 0.8305\n",
            "Epoch 15/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8380 - mae: 0.7221 - val_loss: 1.0033 - val_mae: 0.8135\n",
            "Epoch 16/100\n",
            "72000/72000 [==============================] - 4s 51us/step - loss: 0.8362 - mae: 0.7208 - val_loss: 1.0457 - val_mae: 0.8408\n",
            "Epoch 17/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8309 - mae: 0.7184 - val_loss: 1.0333 - val_mae: 0.8342\n",
            "Epoch 18/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8295 - mae: 0.7172 - val_loss: 1.0368 - val_mae: 0.8363\n",
            "Epoch 19/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8269 - mae: 0.7162 - val_loss: 1.0353 - val_mae: 0.8341\n",
            "Epoch 20/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8260 - mae: 0.7158 - val_loss: 1.0360 - val_mae: 0.8362\n",
            "Epoch 21/100\n",
            "72000/72000 [==============================] - 4s 51us/step - loss: 0.8226 - mae: 0.7137 - val_loss: 1.0385 - val_mae: 0.8377\n",
            "Epoch 22/100\n",
            "72000/72000 [==============================] - 4s 49us/step - loss: 0.8217 - mae: 0.7134 - val_loss: 1.0416 - val_mae: 0.8403\n",
            "Epoch 23/100\n",
            "72000/72000 [==============================] - 3s 48us/step - loss: 0.8207 - mae: 0.7133 - val_loss: 1.0455 - val_mae: 0.8436\n",
            "Epoch 24/100\n",
            "72000/72000 [==============================] - 3s 49us/step - loss: 0.8195 - mae: 0.7125 - val_loss: 1.0411 - val_mae: 0.8406\n",
            "Epoch 25/100\n",
            "72000/72000 [==============================] - 3s 48us/step - loss: 0.8137 - mae: 0.7097 - val_loss: 1.0403 - val_mae: 0.8395\n",
            "Epoch 26/100\n",
            "72000/72000 [==============================] - 4s 50us/step - loss: 0.8126 - mae: 0.7089 - val_loss: 1.0462 - val_mae: 0.8422\n",
            "Epoch 27/100\n",
            "72000/72000 [==============================] - 4s 51us/step - loss: 0.8117 - mae: 0.7079 - val_loss: 1.0385 - val_mae: 0.8394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyB9Kn65Nyjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test values\n",
        "test_users = ratings_test['user_emb_id'].values\n",
        "test_movies = ratings_test['movie_emb_id'].values\n",
        "test_ratings = ratings_test['rating'].values\n",
        "test_gender = ratings_test['gender'].values\n",
        "test_age = ratings_test['age'].values\n",
        "\n",
        "preddict_model_gen1 = NCF_G_model1.predict([test_users,test_movies, test_gender, test_age])\n",
        "test_predict1 = pd.DataFrame(data=preddict_model_gen1, columns=['prediction'])\n",
        "test_predict1['actual_rating'] = test_ratings\n",
        "\n",
        "MAE1 = np.sum(abs(test_predict1['actual_rating']-test_predict1['prediction']))/test_predict1.shape[0]\n",
        "print(\"MAE = \"+ str(MAE1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH43WLTjalnH",
        "colab_type": "code",
        "outputId": "2576e924-e4f2-4136-cbb6-0f7fe1b2b5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "pip install deepctr[gpu]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deepctr[gpu] in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deepctr[gpu]) (2.10.0)\n",
            "Collecting tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 29kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->deepctr[gpu]) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->deepctr[gpu]) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (2.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.9.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (46.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0; extra == \"gpu\"->deepctr[gpu]) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKP9g9BFaSxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deepctr.models import DeepFM\n",
        "from deepctr.inputs import SparseFeat, get_feature_names\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OYVT8ohat2r",
        "colab_type": "code",
        "outputId": "899bc97e-b587-4764-8106-47fee51ff445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for feat in ['user_emb_id','movie_emb_id', 'gender', 'age']:\n",
        "        lbe = LabelEncoder()\n",
        "        ratings_train[feat] = lbe.fit_transform(ratings_train[feat])\n",
        "\n",
        "\n",
        "for feat in ['user_emb_id','movie_emb_id', 'gender', 'age']:\n",
        "        lbe = LabelEncoder()\n",
        "        ratings_test[feat] = lbe.fit_transform(ratings_test[feat])\n",
        "\n",
        "\n",
        "fixlen_feature_columns = [SparseFeat(feat, ratings_train[feat].nunique(), embedding_dim=20)\n",
        "                              for feat in ['user_emb_id','movie_emb_id', 'gender', 'age']]\n",
        "linear_feature_columns = fixlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns\n",
        "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "print(feature_names)\n",
        "\n",
        "\n",
        "model_deepFM = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
        "model_deepFM.compile(\"adam\", \"mse\", metrics=['mae'])\n",
        "\n",
        "train_model_deepFM_input = {name: ratings_train[name].values for name in feature_names}\n",
        "\n",
        "test_model_deepFM_input = {name: ratings_test[name].values for name in feature_names}\n",
        "\n",
        "history = model_deepFM.fit(train_model_deepFM_input, train_ratings, epochs=30,  verbose=1, validation_split=0.1, batch_size = 1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user_emb_id', 'movie_emb_id', 'gender', 'age']\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "72000/72000 [==============================] - 162s 2ms/step - loss: 1.0091 - mae: 0.7970 - val_loss: 0.9776 - val_mae: 0.7931\n",
            "Epoch 2/30\n",
            "72000/72000 [==============================] - 160s 2ms/step - loss: 0.8946 - mae: 0.7408 - val_loss: 1.0196 - val_mae: 0.8186\n",
            "Epoch 3/30\n",
            "72000/72000 [==============================] - 163s 2ms/step - loss: 0.8301 - mae: 0.7044 - val_loss: 1.0537 - val_mae: 0.8321\n",
            "Epoch 4/30\n",
            "72000/72000 [==============================] - 165s 2ms/step - loss: 0.7857 - mae: 0.6793 - val_loss: 1.1223 - val_mae: 0.8644\n",
            "Epoch 5/30\n",
            "72000/72000 [==============================] - 164s 2ms/step - loss: 0.7526 - mae: 0.6596 - val_loss: 1.1394 - val_mae: 0.8685\n",
            "Epoch 6/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.7369 - mae: 0.6482 - val_loss: 1.1207 - val_mae: 0.8579\n",
            "Epoch 7/30\n",
            "72000/72000 [==============================] - 165s 2ms/step - loss: 0.7226 - mae: 0.6400 - val_loss: 1.0936 - val_mae: 0.8450\n",
            "Epoch 8/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.7158 - mae: 0.6347 - val_loss: 1.1075 - val_mae: 0.8543\n",
            "Epoch 9/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.7104 - mae: 0.6305 - val_loss: 1.0913 - val_mae: 0.8444\n",
            "Epoch 10/30\n",
            "72000/72000 [==============================] - 163s 2ms/step - loss: 0.7022 - mae: 0.6269 - val_loss: 1.1133 - val_mae: 0.8554\n",
            "Epoch 11/30\n",
            "72000/72000 [==============================] - 165s 2ms/step - loss: 0.7008 - mae: 0.6263 - val_loss: 1.1269 - val_mae: 0.8606\n",
            "Epoch 12/30\n",
            "72000/72000 [==============================] - 160s 2ms/step - loss: 0.6973 - mae: 0.6239 - val_loss: 1.1504 - val_mae: 0.8703\n",
            "Epoch 13/30\n",
            "72000/72000 [==============================] - 160s 2ms/step - loss: 0.6956 - mae: 0.6234 - val_loss: 1.0897 - val_mae: 0.8433\n",
            "Epoch 14/30\n",
            "72000/72000 [==============================] - 160s 2ms/step - loss: 0.6910 - mae: 0.6204 - val_loss: 1.1254 - val_mae: 0.8593\n",
            "Epoch 15/30\n",
            "72000/72000 [==============================] - 161s 2ms/step - loss: 0.6911 - mae: 0.6210 - val_loss: 1.1498 - val_mae: 0.8725\n",
            "Epoch 16/30\n",
            "72000/72000 [==============================] - 158s 2ms/step - loss: 0.6885 - mae: 0.6186 - val_loss: 1.1224 - val_mae: 0.8591\n",
            "Epoch 17/30\n",
            "72000/72000 [==============================] - 160s 2ms/step - loss: 0.6858 - mae: 0.6169 - val_loss: 1.1243 - val_mae: 0.8610\n",
            "Epoch 18/30\n",
            "72000/72000 [==============================] - 161s 2ms/step - loss: 0.6831 - mae: 0.6176 - val_loss: 1.1372 - val_mae: 0.8681\n",
            "Epoch 19/30\n",
            "72000/72000 [==============================] - 163s 2ms/step - loss: 0.6819 - mae: 0.6155 - val_loss: 1.1629 - val_mae: 0.8763\n",
            "Epoch 20/30\n",
            "72000/72000 [==============================] - 159s 2ms/step - loss: 0.6807 - mae: 0.6151 - val_loss: 1.1184 - val_mae: 0.8555\n",
            "Epoch 21/30\n",
            "72000/72000 [==============================] - 159s 2ms/step - loss: 0.6802 - mae: 0.6153 - val_loss: 1.1239 - val_mae: 0.8564\n",
            "Epoch 22/30\n",
            "72000/72000 [==============================] - 158s 2ms/step - loss: 0.6789 - mae: 0.6136 - val_loss: 1.1278 - val_mae: 0.8602\n",
            "Epoch 23/30\n",
            "72000/72000 [==============================] - 161s 2ms/step - loss: 0.6768 - mae: 0.6126 - val_loss: 1.1481 - val_mae: 0.8710\n",
            "Epoch 24/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.6770 - mae: 0.6122 - val_loss: 1.1743 - val_mae: 0.8827\n",
            "Epoch 25/30\n",
            "72000/72000 [==============================] - 159s 2ms/step - loss: 0.6754 - mae: 0.6117 - val_loss: 1.1438 - val_mae: 0.8682\n",
            "Epoch 26/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.6748 - mae: 0.6113 - val_loss: 1.1319 - val_mae: 0.8629\n",
            "Epoch 27/30\n",
            "72000/72000 [==============================] - 158s 2ms/step - loss: 0.6724 - mae: 0.6101 - val_loss: 1.1251 - val_mae: 0.8601\n",
            "Epoch 28/30\n",
            "72000/72000 [==============================] - 159s 2ms/step - loss: 0.6731 - mae: 0.6109 - val_loss: 1.1615 - val_mae: 0.8751\n",
            "Epoch 29/30\n",
            "72000/72000 [==============================] - 159s 2ms/step - loss: 0.6708 - mae: 0.6098 - val_loss: 1.2164 - val_mae: 0.8983\n",
            "Epoch 30/30\n",
            "72000/72000 [==============================] - 162s 2ms/step - loss: 0.6721 - mae: 0.6089 - val_loss: 1.1456 - val_mae: 0.8659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-141b3e03391a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_deepFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model_deepFM_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mvisual_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mpred_deepFM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_deepFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_deepFM_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mtest_predict_deepFM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_deepFM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'visual_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3xhO0zKAQYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visual_results(history)\n",
        "save_model(model_deepFM, \"task5_deepFM\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cURbsv3y1Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visual_results(history):\n",
        "  plt.plot(history.history['mae'])\n",
        "  plt.plot(history.history['val_mae'])\n",
        "  plt.title('Model MAE')\n",
        "  plt.ylabel('MAE')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzppcL4cYcAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2df0f1bd-28cf-4867-c56e-fa187565a208"
      },
      "source": [
        "# visual_results(history)\n",
        "pred_deepFM = model_deepFM.predict(test_model_deepFM_input)\n",
        "test_predict_deepFM = pd.DataFrame(data=pred_deepFM, columns=['prediction'])\n",
        "test_predict_deepFM['actual_rating'] = test_ratings\n",
        "MAE_deepFM = np.sum(abs(test_predict_deepFM['actual_rating']-test_predict_deepFM['prediction']))/test_predict_deepFM.shape[0]\n",
        "# save_model(model_deepFM, \"task5_deepFM\")\n",
        "print()\n",
        "print(\"MAE deepFM = \" + str(MAE_deepFM))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MAE deepFM = 0.860973046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft1KV4_tZ5Xs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "fbe52305-3b14-4113-f6f9-a0ca7f436d0f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predicts = np.argmax(pred_deepFM, axis=1)\n",
        "print(confusion_matrix(test_ratings,predicts))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0]\n",
            " [1391    0    0    0    0    0]\n",
            " [2192    0    0    0    0    0]\n",
            " [5182    0    0    0    0    0]\n",
            " [6778    0    0    0    0    0]\n",
            " [4457    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}