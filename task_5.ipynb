{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd5hNS4N+mPXawgl1l+t5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orenshor/eCommerce_project/blob/master/task_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj_Lw7RdBYuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aedf3043-9c05-4e29-dd4d-53bc81c4f4ec"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "from keras.layers import Embedding, Input, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam, Adamax\n",
        "from keras.layers import Concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "punEIpwMBvi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RATING_DATA_TEST_FILE = \"u1.test\"\n",
        "RATING_DATA_TRAIN_FILE = \"u1.base\"\n",
        "MODEL_WEIGHTS_FILE = \"u_emb_weights.h5\"\n",
        "\n",
        "USER_DATA_FILE = 'u.user'\n",
        "MODEL_WEIGHTS_FILE_CORE = 'u_emb_weights'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5c3__4pCz1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import of the data\n",
        "\n",
        "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "movie_cols = ['user_id','movie_id','rating','timestamp']\n",
        "\n",
        "# load users data\n",
        "user_data = pd.read_csv(USER_DATA_FILE, sep='|', engine='python', encoding='latin-1', names=user_cols)\n",
        "\n",
        "# replace values in the data\n",
        "user_data['gender'].replace(['F','M'],['0','1'],inplace=True)\n",
        "user_data['age'] = pd.cut(user_data['age'],bins=[0,18,25,30,40,50,100], labels=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
        "\n",
        "# load movies data\n",
        "ratings_train = pd.read_csv(RATING_DATA_TRAIN_FILE, sep='\\t', engine='python', encoding='latin-1', names=movie_cols)\n",
        "\n",
        "# marge users info and ratings \n",
        "ratings_train = pd.merge(ratings_train, user_data, on='user_id',how='inner')\n",
        "print(ratings_train.head())\n",
        "# train\n",
        "max_userid = ratings_train['user_id'].drop_duplicates().max()\n",
        "max_movieid = ratings_train['movie_id'].drop_duplicates().max()\n",
        "ratings_train['user_emb_id'] = ratings_train['user_id'] - 1\n",
        "ratings_train['movie_emb_id'] = ratings_train['movie_id'] - 1\n",
        "print(str(len(ratings_train))+' ratings loaded from train')\n",
        "\n",
        "# test\n",
        "ratings_test = pd.read_csv(RATING_DATA_TEST_FILE, sep='\\t',   engine='python', encoding='latin-1',  names=movie_cols)\n",
        "ratings_test = pd.merge(ratings_test, user_data, on='user_id', how='inner')\n",
        "print(ratings_test.head())\n",
        "ratings_test['user_emb_id'] = ratings_test['user_id'] - 1\n",
        "ratings_test['movie_emb_id'] = ratings_test['movie_id'] - 1\n",
        "print(str(len(ratings_test))+' ratings loaded from test')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwdPQXcMN6PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train values\n",
        "train_users = ratings_train['user_emb_id'].values\n",
        "train_movies = ratings_train['movie_emb_id'].values\n",
        "train_ratings = ratings_train['rating'].values\n",
        "train_gender = ratings_train['gender'].values\n",
        "train_age = ratings_train['age'].values\n",
        "\n",
        "Test_Users = ratings_test['user_emb_id'].values\n",
        "Test_Movies = ratings_test['movie_emb_id'].values\n",
        "Test_Ratings = ratings_test['rating'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdEgcipNJD73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model from ex. 4 with adjustments\n",
        "def get_ncf_model_gen1(num_users, num_items, latent_dim, hidden_dim,do):\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "    gender_input = Input(shape=(1,), dtype='float32', name = 'gender_input')\n",
        "    age_input = Input(shape=(1,), dtype='float32', name = 'age_input')\n",
        "\n",
        "    NCF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
        "    NCF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
        "    \n",
        "    # Crucial to flatten an embedding vector!\n",
        "    user_latent = Flatten()(NCF_Embedding_User(user_input))\n",
        "    item_latent = Flatten()(NCF_Embedding_Item(item_input))\n",
        "    \n",
        "    # Concat user and item embeddings with gender\n",
        "    conc = Concatenate()([user_latent, item_latent, gender_input, age_input])\n",
        "    drop = Dropout(do)(conc)\n",
        "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
        "    drop2  = Dropout(do)(hid1)\n",
        "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop2)\n",
        "    \n",
        "    model = Model(inputs=[user_input, item_input, gender_input, age_input], outputs=prediction)\n",
        "    print(\"ncf model gender 1\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Lxo5rCJ1VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K_LATENT = 20\n",
        "hidden_dim = 20\n",
        "do = 0.3\n",
        "\n",
        "NCF_G_model1 = get_ncf_model_gen1(max_userid, max_movieid, K_LATENT,hidden_dim, do)\n",
        "NCF_G_model1.compile(loss='mse',optimizer=Adamax(),metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyk_MaFSL9Bk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_ncfg = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE +'_ncfg_'+str(do)+'_'+str(K_LATENT)+'.h5', save_best_only=True)]\n",
        "history_history_ncfg = NCF_G_model1.fit([train_users, train_movies, train_gender, train_age], train_ratings, epochs=100, validation_split=.1, verbose=1, callbacks=callbacks_ncfg, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyB9Kn65Nyjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f5eac0e-3573-479b-86cc-d8f8aa028159"
      },
      "source": [
        "# test values\n",
        "test_users = ratings_test['user_emb_id'].values\n",
        "test_movies = ratings_test['movie_emb_id'].values\n",
        "test_ratings = ratings_test['rating'].values\n",
        "test_gender = ratings_test['gender'].values\n",
        "test_age = ratings_test['age'].values\n",
        "\n",
        "preddict_model_gen = NCF_G_model1.predict([test_users,test_movies, test_gender, test_age])\n",
        "test_predict1 = pd.DataFrame(data=preddict_model_gen, columns=['prediction'])\n",
        "test_predict1['actual_rating'] = test_ratings\n",
        "\n",
        "MAE1 = np.sum(abs(test_predict1['actual_rating']-test_predict1['prediction']))/test_predict1.shape[0]\n",
        "print(\"MAE = \"+ str(MAE1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE = 0.739847119140625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K8vRWn9O6yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ncf_model_gen2(num_users, num_items, latent_dim, hidden_dim,do):\n",
        "    # Input variables\n",
        "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
        "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
        "    gender_input = Input(shape=(1,), dtype='float32', name = 'gender_input')\n",
        "    age_input = Input(shape=(1,), dtype='float32', name = 'age_input')\n",
        "\n",
        "    NCF_Embedding_User = Embedding(input_dim = num_users, output_dim = latent_dim, name = 'user_embedding', input_length=1)\n",
        "    NCF_Embedding_Item = Embedding(input_dim = num_items, output_dim = latent_dim, name = 'item_embedding', input_length=1)   \n",
        "    \n",
        "    # Crucial to flatten an embedding vector!\n",
        "    user_latent = Flatten()(NCF_Embedding_User(user_input))\n",
        "    item_latent = Flatten()(NCF_Embedding_Item(item_input))\n",
        "    \n",
        "    # Concat user and item embeddings with gender\n",
        "    conc = Concatenate()([user_latent, item_latent, gender_input, age_input])\n",
        "    drop = Dropout(0.3)(conc)\n",
        "    hid1 = Dense(hidden_dim, activation='relu')(conc)\n",
        "    drop2  = Dropout(do)(hid1)\n",
        "    hid2 = Dense(hidden_dim,activation='relu')(drop2)\n",
        "    drop3  = Dropout(do)(hid2)\n",
        "    prediction = Dense(1, activation='relu', kernel_initializer='lecun_uniform', name = 'prediction')(drop3)\n",
        "    \n",
        "    model = Model(inputs=[user_input, item_input, gender_input, age_input], outputs=prediction)\n",
        "    print(\"ncf model gender 2\")\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTGDbj8JQSEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K_LATENT = 20\n",
        "hidden_dim = 20\n",
        "do = 0.5\n",
        "NCF_G_model2 = get_ncf_model_gen2(max_userid, max_movieid, K_LATENT, hidden_dim, do)\n",
        "NCF_G_model2.compile(loss='mse',optimizer=Adamax(),metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRO55gEQx8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_ncfg2 = [EarlyStopping('val_loss', patience=20), \n",
        "             ModelCheckpoint(MODEL_WEIGHTS_FILE_CORE+'_ncfg_'+str(do)+'_'+str(K_LATENT)+'.h5', save_best_only=True)]\n",
        "history_history_ncfg2 = GNCFG_model2.fit([Users_train, Movies_train, Gender_train, Age_train], Ratings_train, epochs=100, validation_split=.1, verbose=1, callbacks=callbacks_ncfg2, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}